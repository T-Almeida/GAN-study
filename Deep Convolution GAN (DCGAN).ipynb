{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Deep Convolution Generative Advarsarial Network\n",
    "\n",
    "Here is presented the implementation of the following parper https://arxiv.org/abs/1511.06434\n",
    "\n",
    "Implementation is done in tensorflow using layers API\n",
    "\n",
    "Created by: Tiago Almeida 05/02/2018\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'1.4.0'"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "##### imports\n",
    "import tensorflow as tf\n",
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import os\n",
    "import utils as ut # auxiliar file to help in data visualization\n",
    "\n",
    "#tensorflow version when notebook was created - 1.4.0\n",
    "tf.__version__\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data mnist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting ./data\\train-images-idx3-ubyte.gz\n",
      "Extracting ./data\\train-labels-idx1-ubyte.gz\n",
      "Extracting ./data\\t10k-images-idx3-ubyte.gz\n",
      "Extracting ./data\\t10k-labels-idx1-ubyte.gz\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAUMAAADuCAYAAACjxmWDAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n/wHbi+ItgcumBAAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x21172dd95f8>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "\n",
    "\n",
    "mnist_flat_size = 784\n",
    "\n",
    "#mnist data\n",
    "from tensorflow.examples.tutorials.mnist import input_data\n",
    "mnist = input_data.read_data_sets(\"./data\",one_hot=True)\n",
    "\n",
    "ut.plot_mnist_images(mnist.test.images[0:9])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Code parameters\n",
    "\n",
    "For the architecture of the generator and the discriminator i am gonna try keep loyal to the network on the paper.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "z_dimention = 100\n",
    "mnist_flat_size = 784\n",
    "\n",
    "batch_size = 64\n",
    "epoach = 50000"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Generator network\n",
    "\n",
    "* 2 Deconvolution layers\n",
    "* No pooling layers\n",
    "* Batch normalization after convolution and before activation\n",
    "* Relu and tanh for output \n",
    "\n",
    "Note: I want that my final image have dimention $28 = 7\\times2\\times2$, so i can start with 7x7 image and upscale it by deconvolutions operations (with stride 2x2 and padding the image with zeros) the result would be a image with 14x14 and doing the same upscaling i get the final image with the size 28x28 (same as mnist :D)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "Z = tf.placeholder(tf.float32, shape=[None, z_dimention], name='x_generator_input')\n",
    "Y = tf.placeholder(tf.float32, shape=[None, 10], name='label_oneHot')\n",
    "isTraining = tf.placeholder_with_default(False, shape=(), name='trainingPhase')\n",
    "\n",
    "def generator(x,train,name):\n",
    "    '''\n",
    "    Generator implemented as MLP\n",
    "    \n",
    "    :param x: tensor with shape (M,100) here M = number of samples\n",
    "    :param train: boolean tensor with indication if we are training or not\n",
    "    :return: tensor with shape (M,28,28,1) corresponding to the image (28x28) mapping between x and data distribution (pData)\n",
    "    '''\n",
    "    with tf.variable_scope(\"generator\",reuse=tf.AUTO_REUSE):\n",
    "        \n",
    "        # 1 fully connected layer to get 7x7x64 output (3136)\n",
    "        fc1 = tf.layers.dense(x, 7*7*64,name=\"fc1_\"+name)\n",
    "        fc1_bn = tf.layers.batch_normalization(fc1, training=train, name=\"fc1_bn_\"+name)\n",
    "        fc_relu1 = tf.nn.relu(fc1_bn,name=\"fc1_fn_\"+name)\n",
    "        \n",
    "        #reshape\n",
    "        r = tf.reshape(fc_relu1, [-1, 7, 7, 64])\n",
    "        \n",
    "        # 1 deconv 64 filters output 14x14x32\n",
    "        deconv1 = tf.layers.conv2d_transpose(r, 64, kernel_size=(5, 5), strides=(2, 2)\n",
    "                                             ,padding='same',name=\"dconv1_\"+name)\n",
    "        deconv1_bn = tf.layers.batch_normalization(deconv1, training=train,name=\"dconv1_bn_\"+name)\n",
    "        dc_relu2 = tf.nn.relu(deconv1_bn,name=\"dconv1_fn_\"+name)\n",
    "\n",
    "        # 2 deconv 1 filters and output 28x28x1\n",
    "        deconv2 = tf.layers.conv2d_transpose(dc_relu2, 1, kernel_size=(5, 5), strides=(2, 2),padding='same'\n",
    "                                             ,name=\"dconv2_\"+name, activation=tf.nn.tanh)\n",
    "\n",
    "        return deconv2\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Discriminator Network\n",
    "* Leaky relu (alpha 0.2 tensorflow default) and tanh for output "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n",
    "X = tf.placeholder(tf.float32, shape=[None, mnist_flat_size], name='x_discriminator_input')\n",
    "\n",
    "def discriminator(x,train,name,drop_rate=0.5):\n",
    "    '''\n",
    "    Discriminator implemented as MLP\n",
    "    \n",
    "    :param x: tensor with shape (M,784) here M = number of samples\n",
    "    :return: tensor with shape (M,1) corresponding to the probability of each sample being true or fake\n",
    "    '''\n",
    "    with tf.variable_scope(\"discriminator\",reuse=tf.AUTO_REUSE):\n",
    "        \n",
    "        #reshape\n",
    "        r = tf.reshape(x, [-1, 28, 28, 1])\n",
    "        \n",
    "        # 1 conv 64 filters output 14x14x32\n",
    "        conv1 = tf.layers.conv2d(r, 64, kernel_size=(5, 5), strides=(2, 2)\n",
    "                                             ,padding='same',name=\"conv1_\"+name)\n",
    "        conv1_bn = tf.layers.batch_normalization(conv1, training=train, name=\"conv1_bn_\"+name)\n",
    "        c_lrelu1 = tf.nn.leaky_relu(conv1_bn,name=\"conv1_fn_\"+name)\n",
    "        \n",
    "        # 2 conv 32 filters and output 7x7x32\n",
    "        conv2 = tf.layers.conv2d(c_lrelu1, 32, kernel_size=(5, 5), strides=(2, 2),padding='same'\n",
    "                                             ,name=\"conv2_\"+name)\n",
    "        conv2_bn = tf.layers.batch_normalization(conv2, training=train, name=\"conv2_bn_\"+name)\n",
    "        c_relu2 = tf.nn.relu(conv2_bn, name=\"conv2_fn_\"+name)\n",
    "        \n",
    "        #flatten\n",
    "        flatten = tf.layers.flatten(c_relu2)\n",
    "        \n",
    "        fc1 = tf.layers.dense(flatten, 7*7*32,name=\"fc1_\"+name,activation=tf.nn.relu)\n",
    "        fc1_drop = tf.layers.dropout(fc1,rate = drop_rate, training=train)\n",
    "        \n",
    "        fc2 = tf.layers.dense(fc1_drop, 256,name=\"fc2_\"+name,activation=tf.nn.relu)\n",
    "        fc2_drop = tf.layers.dropout(fc2,rate = drop_rate, training=train)\n",
    "        \n",
    "        fc3 = tf.layers.dense(fc2_drop, 1,name=\"fc3_\"+name, activation=None)\n",
    "        \n",
    "        sig_fc3 = tf.nn.sigmoid(fc3)\n",
    "        \n",
    "        return sig_fc3,fc3\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loss functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tensor(\"discriminator_1/fc3_d_/BiasAdd:0\", shape=(?, 1), dtype=float32)\n",
      "Tensor(\"discriminator/fc3_d_/BiasAdd:0\", shape=(?, 1), dtype=float32)\n",
      "Tensor(\"generator/dconv2_g_/Tanh:0\", shape=(?, 28, 28, 1), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "#using now the xentropy (TODO use the default)\n",
    "generated_sample = generator(Z,isTraining,\"g_\")\n",
    "d_fake_prob, d_fake_logits = discriminator(generated_sample,isTraining,\"d_\")\n",
    "\n",
    "#normalize between -1 1, perhaps more effecient to cache the results or pre process\n",
    "X_tanh_normalize = (X-0.5)*2\n",
    "d_true_prob, d_true_logits = discriminator(X_tanh_normalize,isTraining,\"d_\")\n",
    "\n",
    "alternative_loss = True\n",
    "\n",
    "print(d_true_logits)\n",
    "print(d_fake_logits)\n",
    "print(generated_sample)\n",
    "#try avoid log(0)\n",
    "eps = 1e-8\n",
    "\n",
    "def xentropy_sigmoid(logits,labels):\n",
    "    return tf.reduce_mean(tf.nn.sigmoid_cross_entropy_with_logits(logits=logits, labels=labels))\n",
    "\n",
    "with tf.name_scope(\"discriminator_loss\"):\n",
    "    if alternative_loss:\n",
    "        d_loss = xentropy_sigmoid(d_true_logits,tf.ones_like(d_true_logits)) + xentropy_sigmoid(d_fake_logits,tf.zeros_like(d_fake_logits)) \n",
    "    else:\n",
    "        d_loss = -tf.reduce_mean(tf.log(d_true_prob + eps) + tf.log(1. - d_fake_prob + eps))\n",
    "\n",
    "\n",
    "with tf.name_scope(\"generator_loss\"):\n",
    "    if alternative_loss:\n",
    "        g_loss = xentropy_sigmoid(d_fake_logits, tf.ones_like(d_fake_logits))\n",
    "    else:\n",
    "        g_loss = -tf.reduce_mean(tf.log(d_fake_prob + eps))\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Geting the trainable variables for generator and the discriminator (disadvantage of using layers API)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[<tf.Variable 'generator/fc1_g_/kernel:0' shape=(100, 3136) dtype=float32_ref>, <tf.Variable 'generator/fc1_g_/bias:0' shape=(3136,) dtype=float32_ref>, <tf.Variable 'generator/fc1_bn_g_/gamma:0' shape=(3136,) dtype=float32_ref>, <tf.Variable 'generator/fc1_bn_g_/beta:0' shape=(3136,) dtype=float32_ref>, <tf.Variable 'generator/dconv1_g_/kernel:0' shape=(5, 5, 64, 64) dtype=float32_ref>, <tf.Variable 'generator/dconv1_g_/bias:0' shape=(64,) dtype=float32_ref>, <tf.Variable 'generator/dconv1_bn_g_/gamma:0' shape=(64,) dtype=float32_ref>, <tf.Variable 'generator/dconv1_bn_g_/beta:0' shape=(64,) dtype=float32_ref>, <tf.Variable 'generator/dconv2_g_/kernel:0' shape=(5, 5, 1, 64) dtype=float32_ref>, <tf.Variable 'generator/dconv2_g_/bias:0' shape=(1,) dtype=float32_ref>]\n",
      "[<tf.Variable 'discriminator/conv1_d_/kernel:0' shape=(5, 5, 1, 64) dtype=float32_ref>, <tf.Variable 'discriminator/conv1_d_/bias:0' shape=(64,) dtype=float32_ref>, <tf.Variable 'discriminator/conv1_bn_d_/gamma:0' shape=(64,) dtype=float32_ref>, <tf.Variable 'discriminator/conv1_bn_d_/beta:0' shape=(64,) dtype=float32_ref>, <tf.Variable 'discriminator/conv2_d_/kernel:0' shape=(5, 5, 64, 32) dtype=float32_ref>, <tf.Variable 'discriminator/conv2_d_/bias:0' shape=(32,) dtype=float32_ref>, <tf.Variable 'discriminator/conv2_bn_d_/gamma:0' shape=(32,) dtype=float32_ref>, <tf.Variable 'discriminator/conv2_bn_d_/beta:0' shape=(32,) dtype=float32_ref>, <tf.Variable 'discriminator/fc1_d_/kernel:0' shape=(1568, 1568) dtype=float32_ref>, <tf.Variable 'discriminator/fc1_d_/bias:0' shape=(1568,) dtype=float32_ref>, <tf.Variable 'discriminator/fc2_d_/kernel:0' shape=(1568, 256) dtype=float32_ref>, <tf.Variable 'discriminator/fc2_d_/bias:0' shape=(256,) dtype=float32_ref>, <tf.Variable 'discriminator/fc3_d_/kernel:0' shape=(256, 1) dtype=float32_ref>, <tf.Variable 'discriminator/fc3_d_/bias:0' shape=(1,) dtype=float32_ref>]\n"
     ]
    }
   ],
   "source": [
    "generator_variables = [var for var in tf.trainable_variables() if 'g_' in var.name]\n",
    "discriminator_variables = [var for var in tf.trainable_variables() if ('d_' in var.name or 'c_' in var.name)]\n",
    "\n",
    "# kernel = weight\n",
    "print(generator_variables)\n",
    "print(discriminator_variables)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoach 0\n",
      "Discriminator loss:  1.49978\n",
      "Generator loss: 1.14463\n",
      "(9, 100)\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'remap' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-8-cfc73d028a2d>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     35\u001b[0m         \u001b[0mgenerated_images\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mgenerated_sample\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0meval\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msession\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0msess\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mfeed_dict\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m{\u001b[0m\u001b[0mZ\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mz_new\u001b[0m\u001b[1;33m}\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m9\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m784\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     36\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 37\u001b[1;33m         \u001b[0mut\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mplot_mnist_images\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mremap\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m: name 'remap' is not defined"
     ]
    }
   ],
   "source": [
    "lr=0.001\n",
    "with tf.name_scope(\"discriminator_train\"):\n",
    "    d_optimizer = tf.train.AdamOptimizer(learning_rate=1e-4,beta1=0.1)\n",
    "    d_train_op = d_optimizer.minimize(d_loss, var_list=discriminator_variables) # note minimizing negative loss is the same as maximizing, tf dont have maximizing\n",
    "\n",
    "with tf.name_scope(\"generator_train\"):\n",
    "    g_optimizer = tf.train.AdamOptimizer(learning_rate=2e-4,beta1=0.3)\n",
    "    g_train_op = g_optimizer.minimize(g_loss,var_list=generator_variables)\n",
    "\n",
    "\n",
    "## Start graph computations and algorithm\n",
    "\n",
    "sess = tf.Session()\n",
    "sess.run(tf.global_variables_initializer())\n",
    "\n",
    "for i in range(epoach+1):\n",
    "    x_train,y_train = mnist.train.next_batch(batch_size)\n",
    "    \n",
    "    #print(y_one_hot)\n",
    "    #first discriminator\n",
    "    _, d_loss_value = sess.run([d_train_op, d_loss], feed_dict={X: x_train, isTraining:True , Z: ut.random_Z(batch_size,n=z_dimention)})\n",
    "    #second generator\n",
    "    _, g_loss_value = sess.run([g_train_op, g_loss], feed_dict={Z: ut.random_Z(batch_size,n=z_dimention),isTraining:True})\n",
    "\n",
    "    if i%500 == 0:\n",
    "        print(\"Epoach\",i)\n",
    "        print(\"Discriminator loss: \",d_loss_value)\n",
    "        print(\"Generator loss:\",g_loss_value)\n",
    "        #print(\"D_sample\",d_sample)\n",
    "        #print(\"G_sample\",g_sample)\n",
    "        \n",
    "        #visual progress of training\n",
    "        z_new = ut.random_Z(9,n=z_dimention)\n",
    "        print(z_new.shape)\n",
    "        generated_images = generated_sample.eval(session=sess,feed_dict={Z: z_new}).reshape((9,784))\n",
    "\n",
    "        ut.plot_mnist_images(remap)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "### Testing the classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "sess.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
