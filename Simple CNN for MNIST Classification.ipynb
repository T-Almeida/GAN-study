{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Simple NN\n",
    "\n",
    "Created by: Tiago Almeida 03/02/2018"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'1.4.0'"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "##imports\n",
    "import tensorflow as tf\n",
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import os\n",
    "import utils as ut # auxiliar file to help in data visualization\n",
    "\n",
    "#tensorflow version when notebook was created - 1.4.0\n",
    "tf.__version__\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data mnist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#mnist data\n",
    "from tensorflow.examples.tutorials.mnist import input_data\n",
    "mnist = input_data.read_data_sets(\"./data\")\n",
    "\n",
    "#reset graph using during notebook development\n",
    "tf.reset_default_graph()\n",
    "\n",
    "ut.plot_mnist_images_label(mnist.test.images[0:9],mnist.test.labels[0:9])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### CNN model\n",
    "\n",
    "Here i will use the model in the tensorflow example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Now the imput is the image it self no need to flat\n",
    "\n",
    "X = tf.placeholder(tf.float32,shape=(None,784),name = \"input\")\n",
    "X_reshape = tf.reshape(X, shape=[-1, 28, 28, 1])\n",
    "Y = tf.placeholder(tf.float32,shape=(None,10),name = \"y\")\n",
    "isTraining = tf.placeholder_with_default(False, shape=(), name='trainingPhase')\n",
    "\n",
    "def classifier(x,train,name,drop_rate=0.5):\n",
    "    '''\n",
    "    Classifier network\n",
    "    \n",
    "    :param x: tensor with shape (M,28,28) here M = number of samples\n",
    "    :param train: boolean tensor with indication if we are training or not\n",
    "    :return: tensor with shape (M,10) corresponding to the logits\n",
    "    '''\n",
    "    with tf.name_scope(\"classifier_\"+name):\n",
    "        \n",
    "        # Convolution Layer with 32 filters and a kernel size of (3,3)\n",
    "        conv1 = tf.layers.conv2d(x, 32, 3, activation=tf.nn.relu,name=\"conv1_\"+name)\n",
    "        # Max Pooling (down-sampling) with strides of (2,2) and kernel size of (2,2)\n",
    "        conv1 = tf.layers.max_pooling2d(conv1, 2, 2,name=\"pool1_\"+name)\n",
    "\n",
    "        # Convolution Layer with 64 filters and a kernel size of (3,3)\n",
    "        conv2 = tf.layers.conv2d(conv1, 64, 3, activation=tf.nn.relu,name=\"conv2_\"+name)\n",
    "        # Max Pooling (down-sampling) with strides of (2,2) and kernel size of (2,2)\n",
    "        conv2 = tf.layers.max_pooling2d(conv2, 2, 2,name=\"pool1_\"+name)\n",
    "\n",
    "        # Flatten the data\n",
    "        fc1 = tf.layers.flatten(conv2,name=\"flatten_\"+name)\n",
    "\n",
    "        # Fully connected layer (in tf contrib folder for now)\n",
    "        fc1 = tf.layers.dense(fc1, 1024,name=\"fc1_\"+name)\n",
    "        # Apply Dropout (if is_training is False, dropout is not applied)\n",
    "        fc1 = tf.layers.dropout(fc1, rate=drop_rate, training=train,name=\"dropout1_\"+name)\n",
    "\n",
    "        # Output layer, class prediction\n",
    "        out = tf.layers.dense(fc1, 10,name=\"output_\"+name)\n",
    "\n",
    "        return out\n",
    "\n",
    "clf_cnn = classifier(X_reshape,isTraining,\"clf_cnn\")\n",
    "\n",
    "with tf.name_scope(\"loss_cnn\"):\n",
    "    xentropy = tf.nn.softmax_cross_entropy_with_logits(labels=Y,logits=clf_cnn)\n",
    "    loss_cnn = tf.reduce_mean(xentropy)\n",
    "\n",
    "lr = 0.001\n",
    "with tf.name_scope(\"train_cnn\"):\n",
    "    clf_cnn_variables = [var for var in tf.trainable_variables() if 'clf_cnn' in var.name] #this line is optional but i want to keep consistence\n",
    "    train_cnn_op = tf.train.AdamOptimizer(lr).minimize(loss_cnn,var_list=clf_cnn_variables)\n",
    "    \n",
    "with tf.name_scope(\"predict_cnn\"):\n",
    "    predict_cnn = tf.argmax(clf_cnn, 1)\n",
    "    #i am calculate a acc with numpy since i need to use batch iterations for test set (no need to do in tf) \n",
    "    acc_cnn = tf.reduce_mean(tf.cast(tf.equal(predict_cnn, tf.argmax(Y, 1)), tf.float32))\n",
    "\n",
    "#since i am using gpu i need to run the test set in batchs\n",
    "def acc(x,labels):\n",
    "    test_size = mnist.test.num_examples\n",
    "    \n",
    "    predict = np.zeros(shape=test_size, dtype=np.int)\n",
    "    \n",
    "    #list with start and end index for batch iteration\n",
    "    test_batch = zip(range(0, test_size, batch_size), range(batch_size, test_size + 1, batch_size))\n",
    "    \n",
    "    for start,end in test_batch:\n",
    "        predict[start:end] = predict_cnn.eval(session=sess,feed_dict={X:x[start:end]})\n",
    "    \n",
    "    print(\"acc:\", np.mean(predict==labels)) \n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### It's trainning time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 128\n",
    "epoach = 10000\n",
    "\n",
    "#tensorflow session\n",
    "sess = tf.Session()\n",
    "sess.run(tf.global_variables_initializer())\n",
    "\n",
    "for i in range(epoach):\n",
    "    \n",
    "    x_train,y_train = mnist.train.next_batch(batch_size=batch_size)\n",
    "    \n",
    "    _,it_loss = sess.run([train_cnn_op,loss_cnn], feed_dict = {X:x_train, Y:ut.one_hot(y_train)})\n",
    "    \n",
    "    if i%100==0:\n",
    "        print(\"Epoach:\",i,\"Loss:\",it_loss,\"Acc:\",acc(mnist.test.images,mnist.test.labels))\n",
    "        if i%1000==0:\n",
    "            labels = predict_cnn.eval(session=sess, feed_dict = {X:mnist.test.images[0:9], Y:ut.one_hot(mnist.test.labels[0:9])})\n",
    "            ut.plot_mnist_images_label(mnist.test.images[0:9],mnist.test.labels[0:9],cls_pred=labels)\n",
    "        \n",
    "        \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "sess.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
